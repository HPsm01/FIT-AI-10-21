import os, time, json, math, re
import numpy as np
import cv2
import boto3
import mediapipe as mp
import requests
from urllib.parse import unquote_plus
from datetime import datetime
# MediaPipe Pose ì´ˆê¸°í™”
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=1,  # ì†ë„ í–¥ìƒì„ ìœ„í•´ 1ë¡œ ë‚®ì¶¤
    smooth_landmarks=True,
    enable_segmentation=False,
    smooth_segmentation=True,
    min_detection_confidence=0.1,  # í¬ì¦ˆ ê°ì§€ ì„±ê³µë¥  í–¥ìƒì„ ìœ„í•´ 0.1ë¡œ ë‚®ì¶¤
    min_tracking_confidence=0.1    # í¬ì¦ˆ ê°ì§€ ì„±ê³µë¥  í–¥ìƒì„ ìœ„í•´ 0.1ë¡œ ë‚®ì¶¤
)
mp_drawing = mp.solutions.drawing_utils
print("ì´ˆê¸°í™” ì™„ë£Œ! - ì†ë„ ìµœì í™” ì„¤ì • ì ìš©")
# =========================
# AWS ì„¤ì •
# =========================
queue_url = "https://sqs.ap-northeast-2.amazonaws.com/302263062071/fitvideo_analysis"
bucket_name = "thefit-bucket"
region_name = "ap-northeast-2"

sqs = boto3.client("sqs", region_name=region_name)
s3  = boto3.client("s3", region_name=region_name)

# =========================
# ì„œë²„ ì£¼ì†Œ
# =========================
BASE_URL = "http://13.209.67.129:8000"

# ì²˜ë¦¬ëœ ë™ì˜ìƒ ì¶”ì 
processed_videos = set()
ROOT_PREFIX = "fitvideoresult"
# exercise_id -> í´ë”ëª… ë§¤í•‘
EXERCISE_MAP = {
    1: "deadlift",
    2: "squat",
    3: "bench_press",
}

# =========================
# ìœ í‹¸
# =========================
def get_message():
    response = sqs.receive_message(
        QueueUrl=queue_url,
        MaxNumberOfMessages=1,
        WaitTimeSeconds=10,
        VisibilityTimeout=30
    )
    return response.get("Messages", [None])[0]

def delete_message(receipt_handle):
    sqs.delete_message(QueueUrl=queue_url, ReceiptHandle=receipt_handle)

def download_video(object_key):
    filename = object_key.split("/")[-1]
    local_path = f"/content/{filename}"
    s3.download_file(bucket_name, object_key, local_path)
    print(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {local_path}")
    return local_path

def parse_filename(filename):

    base = filename
    if base.endswith(".mp4"):
        base = base[:-4]
    parts = base.split("_")
    if len(parts) < 4:
        return None, None, None, None
    try:
        uid = int(parts[0])
        uname = parts[1]
        load_kg = float(parts[2])
        timestamp = parts[3]
        return uid, uname, load_kg, timestamp
    except Exception:
        return None, None, None, None

def ts_to_yyyymmdd(ts: str) -> str:
    # ts: yyyyMMddHHmmssSSS(17ìë¦¬) ê°€ì • â†’ ì• 8ìë¦¬ ë‚ ì§œ
    try:
        return ts[:8]
    except Exception:
        return ""

def get_next_set_no(user_id: int, user_name: str, yyyymmdd: str, exercise: str) -> int:
    prefix = f"{ROOT_PREFIX}/{user_id}_{user_name}/{yyyymmdd}/{exercise}/"
    continuation_token = None
    total = 0

    while True:
        kwargs = {"Bucket": bucket_name, "Prefix": prefix}
        if continuation_token:
            kwargs["ContinuationToken"] = continuation_token

        resp = s3.list_objects_v2(**kwargs)
        contents = resp.get("Contents", [])
        # ë¶„ì„ëœ mp4ë§Œ ì¹´ìš´íŠ¸ (setX_*.mp4)
        for obj in contents:
            key = obj["Key"]
            if key.lower().endswith(".mp4") and "/set" in key:
                total += 1

        if resp.get("IsTruncated"):
            continuation_token = resp.get("NextContinuationToken")
        else:
            break

    # ê¸°ì¡´ ê°œìˆ˜ + 1ì´ ë‹¤ìŒ set ë²ˆí˜¸
    return total + 1

# =========================
# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
# =========================
def preprocess_frame(frame):
    """í”„ë ˆì„ ì „ì²˜ë¦¬ë¡œ í¬ì¦ˆ ê°ì§€ ì„±ëŠ¥ í–¥ìƒ"""
    try:
        # 1. ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)
        
        # 2. ëŒ€ë¹„ í–¥ìƒ (CLAHE)
        lab = cv2.cvtColor(denoised, cv2.COLOR_BGR2LAB)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        lab[:,:,0] = clahe.apply(lab[:,:,0])
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        # 3. ì„ ëª…ë„ í–¥ìƒ
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        return sharpened
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return frame

# =========================
# ë¹„ë””ì˜¤ ìƒì„±/ë¶„ì„
# =========================
def create_overlay_video(video_path, analysis_results, output_path):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ì˜¤ë²„ë ˆì´ë¡œ í‘œì‹œí•œ ë™ì˜ìƒ ìƒì„±"""
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,  # ë” ì •í™•í•œ ê°ì§€
        smooth_landmarks=True,  # ëœë“œë§ˆí¬ ìŠ¤ë¬´ë”©
        enable_segmentation=False,
        smooth_segmentation=True,
        min_detection_confidence=0.01,  # ê·¹ë„ë¡œ ê´€ëŒ€í•œ ì„ê³„ê°’
        min_tracking_confidence=0.01    # ê·¹ë„ë¡œ ê´€ëŒ€í•œ ì„ê³„ê°’
    )

    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 720
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1280

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    frame_count = 0
    rep_results = analysis_results.get("rep_results", [])
    current_rep = 0

    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.8
    thickness = 2

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        overlay_frame = frame.copy()

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)

        if results.pose_landmarks:
            mp.solutions.drawing_utils.draw_landmarks(
                overlay_frame,
                results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS
            )
            for rep_info in rep_results:
                if rep_info.get("frame_start", 0) <= frame_count <= rep_info.get("frame_end", 10**9):
                    current_rep = rep_info.get("rep", 0)
                    break

        # ìƒë‹¨ íŒ¨ë„
        panel_height = 120
        cv2.rectangle(overlay_frame, (0, 0), (width, panel_height), (0, 0, 0), -1)
        cv2.rectangle(overlay_frame, (0, 0), (width, panel_height), (255, 255, 255), 2)

        info_texts = [
            f"Rep: {current_rep}",
            f"Total: {analysis_results.get('total_count', 0)}",
            f"Score: {analysis_results.get('score', 0)}",
            f"Grade: {analysis_results.get('grade', 'N/A')}"
        ]

        for i, text in enumerate(info_texts):
            y_pos = 30 + i * 25
            cv2.putText(overlay_frame, text, (20, y_pos), font, font_scale, (255, 255, 255), thickness)

        # í•˜ë‹¨ íŒ¨ë„
        stats_panel_y = height - 80
        cv2.rectangle(overlay_frame, (0, stats_panel_y), (width, height), (0, 0, 0), -1)
        cv2.rectangle(overlay_frame, (0, stats_panel_y), (width, height), (255, 255, 255), 2)

        counts = analysis_results.get("counts", {})
        stats_texts = [
            f"Full Squat: {counts.get('Full Squat', 0)}",
            f"Basic Squat: {counts.get('Basic Squat', 0)}",
            f"Half Squat: {counts.get('Half Squat', 0)}",
            f"Fail Squat: {counts.get('Fail Squat', 0)}"
        ]

        for i, text in enumerate(stats_texts):
            y_pos = stats_panel_y + 25 + i * 15
            cv2.putText(overlay_frame, text, (20, y_pos), font, 0.6, (255, 255, 255), 1)

        if 0 < current_rep <= len(rep_results):
            rep_info = rep_results[current_rep - 1]
            rep_text = f"Rep {current_rep}: {rep_info.get('label', 'N/A')} ({rep_info.get('min_knee_angle', 0)}Â°)"
            cv2.putText(overlay_frame, rep_text, (width//2 - 150, height//2), font, 1.2, (0, 255, 0), 3)

        out.write(overlay_frame)
        frame_count += 1

    cap.release()
    out.release()
    print(f"âœ… ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")

def analyze_squat_with_overlay(video_path):
    """ìŠ¤ì¿¼íŠ¸ ë¶„ì„ ë° ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤ ìƒì„± - ì†ë„ ìµœì í™”"""
    mp_pose = mp.solutions.pose
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,  # ì†ë„ í–¥ìƒì„ ìœ„í•´ 1ë¡œ ë‚®ì¶¤
        smooth_landmarks=True,
        enable_segmentation=False,
        smooth_segmentation=True,
        min_detection_confidence=0.3,  # ì†ë„ í–¥ìƒì„ ìœ„í•´ 0.3ìœ¼ë¡œ ìƒí–¥
        min_tracking_confidence=0.3    # ì†ë„ í–¥ìƒì„ ìœ„í•´ 0.3ìœ¼ë¡œ ìƒí–¥
    )

    MOVE_THRESHOLD_START = 0.0001  # ë” ë¯¼ê°í•œ ì›€ì§ì„ ê°ì§€
    MOVE_THRESHOLD_END = 0.005     # ë” ë¯¼ê°í•œ ì›€ì§ì„ ê°ì§€
    READY_THRESHOLD = 10           # ë” ë¹ ë¥¸ ë¶„ì„ ì‹œì‘
    POST_SQUAT_FREEZE_FRAMES = 30  # ìŠ¤ì¿¼íŠ¸ ê°„ ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ (10 â†’ 30)

    previous_hip = None
    ready_frames = 0
    counting_started = False
    post_squat_wait = 0
    counter = 0
    stage = None
    prev_stage = None
    min_knee_angle = 180
    rep_result_list = []
    counts = {"Half Squat": 0, "Basic Squat": 0, "Full Squat": 0, "Fail Squat": 0}

    frame_analysis = []
    frame_count = 0

    def calculate_angle(a, b, c):
        a, b, c = np.array(a), np.array(b), np.array(c)
        ab = a - b
        cb = c - b
        cosine = np.dot(ab, cb) / (np.linalg.norm(ab) * np.linalg.norm(cb) + 1e-6)
        return np.degrees(np.arccos(np.clip(cosine, -1.0, 1.0)))

    def get_best_leg_angle(lm):
        """ì–‘ìª½ ë‹¤ë¦¬ ì¤‘ ë” ì•ˆì •ì ì¸ ê°ë„ ì„ íƒ"""
        try:
            # ì™¼ìª½ ë‹¤ë¦¬
            left_hip = [lm[mp_pose.PoseLandmark.LEFT_HIP.value].x, lm[mp_pose.PoseLandmark.LEFT_HIP.value].y]
            left_knee = [lm[mp_pose.PoseLandmark.LEFT_KNEE.value].x, lm[mp_pose.PoseLandmark.LEFT_KNEE.value].y]
            left_ankle = [lm[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, lm[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]
            left_angle = calculate_angle(left_hip, left_knee, left_ankle)
            
            # ì˜¤ë¥¸ìª½ ë‹¤ë¦¬
            right_hip = [lm[mp_pose.PoseLandmark.RIGHT_HIP.value].x, lm[mp_pose.PoseLandmark.RIGHT_HIP.value].y]
            right_knee = [lm[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, lm[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]
            right_ankle = [lm[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, lm[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]
            right_angle = calculate_angle(right_hip, right_knee, right_ankle)
            
            # ë” ì•ˆì •ì ì¸ ê°ë„ ì„ íƒ
            if left_angle > 30 and right_angle > 30:
                if abs(left_angle - right_angle) < 25:
                    return (left_angle + right_angle) / 2, left_hip
                else:
                    return max(left_angle, right_angle), left_hip if left_angle > right_angle else right_hip
            elif left_angle > 30:
                return left_angle, left_hip
            elif right_angle > 30:
                return right_angle, right_hip
            else:
                return left_angle, left_hip
        except Exception as e:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì™¼ìª½ ë‹¤ë¦¬ ì‚¬ìš©
            left_hip = [lm[mp_pose.PoseLandmark.LEFT_HIP.value].x, lm[mp_pose.PoseLandmark.LEFT_HIP.value].y]
            left_knee = [lm[mp_pose.PoseLandmark.LEFT_KNEE.value].x, lm[mp_pose.PoseLandmark.LEFT_KNEE.value].y]
            left_ankle = [lm[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, lm[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]
            return calculate_angle(left_hip, left_knee, left_ankle), left_hip

    def record_squat(rep_result_list, counter, label, min_knee_angle, frame_start, frame_end):
        rep_result_list.append({
            "rep": counter,
            "label": label,
            "min_knee_angle": int(min_knee_angle),
            "frame_start": frame_start,
            "frame_end": frame_end
        })

    cap = cv2.VideoCapture(video_path)
    rep_start_frame = 0
    
    # ë™ì˜ìƒ ì •ë³´ ì¶œë ¥
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 720
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1280
    print(f"ğŸ“¹ ë¶„ì„í•  ë™ì˜ìƒ: {width}x{height} @ {fps}fps")
    print(f"âš¡ ì†ë„ ìµœì í™” ì ìš©: 320x240 í”„ë ˆì„, ì „ì²˜ë¦¬ ì œê±°, ì„ê³„ê°’ 0.3")

    # í¬ì¦ˆ ê°ì§€ ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
    pose_detected_frames = 0
    pose_failed_frames = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # ì†ë„ ìµœì í™”: í”„ë ˆì„ í¬ê¸°ë§Œ ì¶•ì†Œí•˜ê³  ì „ì²˜ë¦¬ ì œê±°
        small_frame = cv2.resize(frame, (240, 180), interpolation=cv2.INTER_AREA)  # ë” ì‘ì€ í¬ê¸°ë¡œ ê°ì§€ ì„±ëŠ¥ í–¥ìƒ
        
        # ì „ì²˜ë¦¬ ì—†ì´ ë°”ë¡œ í¬ì¦ˆ ê°ì§€ (ì†ë„ ëŒ€í­ í–¥ìƒ)
        image = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)

        frame_analysis.append({
            "frame": frame_count,
            "has_pose": results.pose_landmarks is not None,
            "stage": stage,
            "knee_angle": None
        })

        if not results.pose_landmarks:
            pose_failed_frames += 1
            # ë¡œê·¸ ë¹ˆë„ ì¤„ì„ (50í”„ë ˆì„ë§ˆë‹¤)
            if frame_count % 50 == 0:
                print(f"âŒ í”„ë ˆì„ {frame_count}: í¬ì¦ˆ ê°ì§€ ì‹¤íŒ¨ (ëˆ„ì : {pose_failed_frames})")
            frame_count += 1
            continue

        pose_detected_frames += 1

        # ë¡œê·¸ ë¹ˆë„ ì¤„ì„ (50í”„ë ˆì„ë§ˆë‹¤)
        if frame_count % 50 == 0:
            print(f"âœ… í”„ë ˆì„ {frame_count}: í¬ì¦ˆ ê°ì§€ ì„±ê³µ (ëˆ„ì : {pose_detected_frames})")

        lm = results.pose_landmarks.landmark
        
        # ì–‘ìª½ ë‹¤ë¦¬ ì¤‘ ë” ì•ˆì •ì ì¸ ê°ë„ ì„ íƒ
        knee_angle, hip = get_best_leg_angle(lm)

        frame_analysis[-1]["knee_angle"] = knee_angle

        # ë””ë²„ê¹…: ê°ë„ ë³€í™” ëª¨ë‹ˆí„°ë§ (50í”„ë ˆì„ë§ˆë‹¤)
        if frame_count % 50 == 0:
            print(f"ğŸ” í”„ë ˆì„ {frame_count}: ë¬´ë¦ ê°ë„ = {knee_angle:.1f}Â°, ë‹¨ê³„ = {stage}")

        move = 0 if previous_hip is None else abs(hip[0] - previous_hip[0]) + abs(hip[1] - previous_hip[1])
        previous_hip = hip

        if not counting_started:
            # ê°ë„ ë³€í™”ë¡œ ìŠ¤ì¿¼íŠ¸ ë™ì‘ ê°ì§€ ì‹œ ì¦‰ì‹œ ì‹œì‘
            if knee_angle < 165:  # ë” ì—„ê²©í•œ ìŠ¤ì¿¼íŠ¸ ì‹œì‘ ì¡°ê±´ (170 â†’ 165)
                counting_started = True
                print(f"ğŸš€ ìŠ¤ì¿¼íŠ¸ ë™ì‘ ê°ì§€! ê°ë„: {knee_angle:.1f}Â° â†’ ë¶„ì„ ì‹œì‘")
            else:
                ready_frames = ready_frames + 1 if move < MOVE_THRESHOLD_START else 0
                if ready_frames >= READY_THRESHOLD:
                    counting_started = True
                    print("- ë¶„ì„ ì‹œì‘ -")
            frame_count += 1
            continue

        if post_squat_wait > 0:
            if move < MOVE_THRESHOLD_START and knee_angle > 150:  # ë” ë¹ ë¥¸ ë‹¤ìŒ ìŠ¤ì¿¼íŠ¸ ê°ì§€
                post_squat_wait -= 1
                frame_count += 1
                continue
            else:
                post_squat_wait = 0

        if counting_started and stage == "up" and move > MOVE_THRESHOLD_END:
            # ë” ì—„ê²©í•œ ì¢…ë£Œ ì¡°ê±´: ì—°ì†ìœ¼ë¡œ ì—¬ëŸ¬ í”„ë ˆì„ì—ì„œ ì´ë™ì´ ê°ì§€ë˜ì–´ì•¼ ì¢…ë£Œ
            if frame_count > 100:  # ìµœì†Œ 100í”„ë ˆì„ì€ ë¶„ì„
                print("âœ… ë§ˆì§€ë§‰ ìŠ¤ì¿¼íŠ¸ ì´í›„ ì´ë™ ê°ì§€ë¨ â†’ ë¶„ì„ ì¢…ë£Œ")
                break
            else:
                print(f"âš ï¸ ë„ˆë¬´ ì¼ì° ì¢…ë£Œ ë°©ì§€: í”„ë ˆì„ {frame_count} (ìµœì†Œ 100í”„ë ˆì„ í•„ìš”)")

        if stage == "down" or (stage is None and knee_angle < 170):  # ë” í˜„ì‹¤ì ì¸ í•˜ê°• ê°ì§€ (175 â†’ 170)
            min_knee_angle = min(min_knee_angle, knee_angle)

        stage = "down" if knee_angle < 155 else "up"  # ë” í˜„ì‹¤ì ì¸ ë‹¨ê³„ ì „í™˜ (160 â†’ 155)

        # ë””ë²„ê¹…: ë‹¨ê³„ ë³€í™” ëª¨ë‹ˆí„°ë§
        if prev_stage != stage and stage is not None:
            print(f"ğŸ”„ ë‹¨ê³„ ë³€í™”: {prev_stage} â†’ {stage} (ê°ë„: {knee_angle:.1f}Â°)")

        if prev_stage == "down" and stage == "up":
            # ìŠ¤ì¿¼íŠ¸ ê°„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ í™•ì¸
            if frame_count - rep_start_frame < 15:  # ìµœì†Œ 15í”„ë ˆì„ ì´ìƒì˜ ë™ì‘ í•„ìš”
                print(f"âš ï¸ ë„ˆë¬´ ë¹ ë¥¸ ìŠ¤ì¿¼íŠ¸ ê°ì§€ ë¬´ì‹œ: {frame_count - rep_start_frame}í”„ë ˆì„ (ìµœì†Œ 15í”„ë ˆì„ í•„ìš”)")
                continue
                
            counter += 1
            # ìš”ì²­ëœ ê²°ê³¼ì— ë§ê²Œ íŒì • ê¸°ì¤€ ìˆ˜ì •
            if 100 >= min_knee_angle > 80:  # 75 â†’ 80ìœ¼ë¡œ ì¡°ì •
                label = "Half Squat"
            elif 80 >= min_knee_angle > 55:  # 60 â†’ 55ë¡œ ì¡°ì •
                label = "Basic Squat"
            elif 55 >= min_knee_angle > 0:   # 60 â†’ 55ë¡œ ì¡°ì •
                label = "Full Squat"
            else:
                label = "Fail Squat"
            print(f"ğŸ¯ {counter}íšŒ ìŠ¤ì¿¼íŠ¸ ê°ì§€! | íŒì •: {label} | ê°ë„: {min_knee_angle:.1f}Â° | í”„ë ˆì„: {rep_start_frame}-{frame_count}")
            counts[label] += 1
            record_squat(rep_result_list, counter, label, min_knee_angle, rep_start_frame, frame_count)
            min_knee_angle = 180
            post_squat_wait = POST_SQUAT_FREEZE_FRAMES

        if stage == "down" and prev_stage != "down":
            rep_start_frame = frame_count

        prev_stage = stage
        frame_count += 1

    cap.release()

    # ë¶„ì„ ê²°ê³¼ ìš”ì•½
    total_frames = len(frame_analysis)
    detected_frames = sum(1 for f in frame_analysis if f["has_pose"])
    detection_rate = (detected_frames / total_frames) * 100 if total_frames > 0 else 0
    
    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
    print(f"   ì´ í”„ë ˆì„: {total_frames}")
    print(f"   í¬ì¦ˆ ê°ì§€: {detected_frames} ({detection_rate:.1f}%)")
    print(f"   í¬ì¦ˆ ê°ì§€ ì„±ê³µ: {pose_detected_frames}")
    print(f"   í¬ì¦ˆ ê°ì§€ ì‹¤íŒ¨: {pose_failed_frames}")
    print(f"   ìŠ¤ì¿¼íŠ¸ íšŸìˆ˜: {counter}")
    print(f"   ìµœì†Œ ê°ë„: {min_knee_angle}Â°")

    # í¬ì¦ˆ ê°ì§€ìœ¨ì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê²½ê³ 
    if detection_rate < 50:
        print(f"âš ï¸ ê²½ê³ : í¬ì¦ˆ ê°ì§€ìœ¨ì´ ë‚®ìŠµë‹ˆë‹¤ ({detection_rate:.1f}%)")

    weight = {"Full Squat": 1.0, "Basic Squat": 0.7, "Half Squat": 0.4}
    raw_score = (
        counts["Full Squat"] * weight["Full Squat"] +
        counts["Basic Squat"] * weight["Basic Squat"] +
        counts["Half Squat"] * weight["Half Squat"]
    )
    max_score = (
        (counts["Full Squat"] + counts["Basic Squat"] + counts["Half Squat"]) * weight["Full Squat"]
    )
    score_ratio = raw_score / max(max_score, 1)
    base_score = score_ratio * 100
    penalty = counts["Fail Squat"] * 3
    final_score = max(0, min(100, int(base_score - penalty)))

    if final_score >= 80:
        msg = "Perfect!!"
    elif final_score >= 60:
        msg = "Great!!"
    elif final_score >= 40:
        msg = "Good!!"
    else:
        msg = "Bad.."

    result = {
        "counts": counts,
        "total_count": counter,
        "score": final_score,
        "grade": msg,
        "rep_results": rep_result_list,
        "frame_analysis": frame_analysis
    }

    output_path = video_path.replace(".mp4", "_analyzed.mp4")
    create_overlay_video(video_path, result, output_path)

    return result, output_path

# =========================
# ë™ì˜ìƒ ì •ê·œí™”
# =========================
def normalize_video(video_path, target_width=1920, target_height=1080, target_fps=29):
    """ë™ì˜ìƒì„ í‘œì¤€ í•´ìƒë„ë¡œ ì •ê·œí™” - 1920x1080 @ 29fps"""
    print(f"ğŸ”„ ë™ì˜ìƒ ì •ê·œí™” ì‹œì‘: {target_width}x{target_height} @ {target_fps}fps")
    
    # ì„ì‹œ ì •ê·œí™”ëœ ë™ì˜ìƒ ê²½ë¡œ
    normalized_path = video_path.replace(".mp4", "_normalized.mp4")
    
    cap = cv2.VideoCapture(video_path)
    original_fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 720
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1280
    
    print(f"ğŸ“¹ ì›ë³¸ ë™ì˜ìƒ: {original_width}x{original_height} @ {original_fps}fps")
    
    # ì •ê·œí™”ê°€ í•„ìš”í•œì§€ í™•ì¸
    if (original_width == target_width and 
        original_height == target_height and 
        original_fps == target_fps):
        print("âœ… ì´ë¯¸ í‘œì¤€ í•´ìƒë„ - ì •ê·œí™” ë¶ˆí•„ìš”")
        cap.release()
        return video_path
    
    # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(normalized_path, fourcc, target_fps, (target_width, target_height))
    
    frame_count = 0
    processed_frames = 0
    
    # FPS ì¡°ì •ì„ ìœ„í•œ í”„ë ˆì„ ê°„ê²© ê³„ì‚°
    frame_interval = original_fps / target_fps
    next_frame_time = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # í˜„ì¬ í”„ë ˆì„ ì‹œê°„
        current_frame_time = frame_count / original_fps
        
        # FPS ì¡°ì •: ëª©í‘œ FPSì— ë§ì¶° í”„ë ˆì„ ì„ íƒ
        if current_frame_time >= next_frame_time:
            # í”„ë ˆì„ ì •ê·œí™”
            normalized_frame = cv2.resize(frame, (target_width, target_height), interpolation=cv2.INTER_AREA)
            
            # ì •ê·œí™”ëœ í”„ë ˆì„ì„ ì¶œë ¥
            out.write(normalized_frame)
            processed_frames += 1
            
            # ë‹¤ìŒ í”„ë ˆì„ ì‹œê°„ ê³„ì‚°
            next_frame_time = processed_frames / target_fps
        
        frame_count += 1
        
        # ì§„í–‰ìƒí™© í‘œì‹œ
        if frame_count % 100 == 0:
            print(f"   ì§„í–‰ë¥ : {frame_count} í”„ë ˆì„ ì½ê¸°, {processed_frames} í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ")
    
    cap.release()
    out.release()
    
    # ì •ê·œí™” ê²°ê³¼ ê²€ì¦
    if os.path.exists(normalized_path):
        verify_cap = cv2.VideoCapture(normalized_path)
        final_fps = int(verify_cap.get(cv2.CAP_PROP_FPS)) or 30
        final_width = int(verify_cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 720
        final_height = int(verify_cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 1280
        verify_cap.release()
        
        print(f"âœ… ë™ì˜ìƒ ì •ê·œí™” ì™„ë£Œ: {processed_frames} í”„ë ˆì„ â†’ {final_width}x{final_height} @ {final_fps}fps")
        print(f"ğŸ” ì •ê·œí™” ê²€ì¦: ì›ë³¸ {original_width}x{original_height}@{original_fps} â†’ ê²°ê³¼ {final_width}x{final_height}@{final_fps}")
        
        # ì •ê·œí™”ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if final_width == target_width and final_height == target_height and final_fps == target_fps:
            print("âœ… ì •ê·œí™” ì„±ê³µ!")
            return normalized_path
        else:
            print("âŒ ì •ê·œí™” ì‹¤íŒ¨ - ì›ë³¸ ë™ì˜ìƒ ë°˜í™˜")
            os.remove(normalized_path)
            return video_path
    else:
        print("âŒ ì •ê·œí™”ëœ ë™ì˜ìƒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
        return video_path

# =========================
# ë©”ì‹œì§€ ì²˜ë¦¬
# =========================
def process_video_message(msg):
    """ë™ì˜ìƒ ë©”ì‹œì§€ ì²˜ë¦¬"""
    try:
        print(f"ğŸ” ë©”ì‹œì§€ ë‚´ìš© í™•ì¸:")
        print(f"   Body: {msg['Body'][:200]}...")

        body = json.loads(msg["Body"])

        # ë©”ì‹œì§€ êµ¬ì¡°
        if "Records" in body:
            object_key = unquote_plus(body["Records"][0]["s3"]["object"]["key"])
            print(f"   ğŸ“ S3 ì´ë²¤íŠ¸ ê°ì§€: {object_key}")
        elif "video_key" in body:
            object_key = body["video_key"]
            print(f"   ë¹„ë””ì˜¤ í‚¤: {object_key}")
        else:
            print(f"   âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ êµ¬ì¡°: {list(body.keys())}")
            print("âŒ ë©”ì‹œì§€ êµ¬ì¡° ì˜¤ë¥˜ â†’ ì‚­ì œ")
            delete_message(msg["ReceiptHandle"])
            return False

        # ì¤‘ë³µ/ë¶„ì„ë³¸ í•„í„°
        if object_key in processed_videos or object_key.endswith("_analyzed.mp4"):
            print(f"âš ï¸ ë¶„ì„ëœ ì˜ìƒ ë˜ëŠ” ì´ë¯¸ ì²˜ë¦¬ëœ ì˜ìƒ: {object_key} â†’ ì‚­ì œ")
            delete_message(msg["ReceiptHandle"])
            return True

        print(f"ìƒˆë¡œìš´ ë™ì˜ìƒ ë¶„ì„ ì‹œì‘: {object_key}")

        # ë‹¤ìš´ë¡œë“œ ë° íŒŒì‹±
        video_path = download_video(object_key)
        user_id, user_name, load_kg, timestamp = parse_filename(os.path.basename(video_path))

        if None in [user_id, user_name, load_kg, timestamp]:
            print("âŒ íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨ â†’ ì‚­ì œ")
            delete_message(msg["ReceiptHandle"])
            return False

        # ë™ì˜ìƒ ì •ê·œí™” (1920x1080 @ 29fps)
        normalized_video_path = normalize_video(video_path)

        # ìµœì‹  ì…ì‹¤ ì¡°íšŒ
        visit_res = requests.get(f"{BASE_URL}/visits/last/{user_id}")
        if visit_res.status_code != 200:
            print("âŒ ì…ì‹¤ ê¸°ë¡ ì—†ìŒ â†’ ì‚­ì œ")
            delete_message(msg["ReceiptHandle"])
            return False
        visit_id = visit_res.json()["id"]

        # ìš´ë™ ë“±ë¡
        workout_data = {
            "user_id": user_id,
            "visit_id": visit_id,
            "exercise_id": 2,  # ìŠ¤ì¿¼íŠ¸ (í•„ìš”ì‹œ ë©”ì‹œì§€/ë©”íƒ€ë°ì´í„°ë¡œ ë°›ì•„ì„œ ë³€ê²½)
            "load_kg": load_kg,
            "s3_key": object_key
        }
        res = requests.post(f"{BASE_URL}/workouts", json=workout_data)
        print("â–¶ POST /workouts:", res.status_code)
        if res.status_code != 200:
            print("âŒ ìš´ë™ ë“±ë¡ ì‹¤íŒ¨:", res.text)
            delete_message(msg["ReceiptHandle"])
            return False

        workout_id   = res.json()["workout_id"]
        exercise_id  = workout_data["exercise_id"]
        exercise_dir = EXERCISE_MAP.get(exercise_id, "squat")

        # ì •ê·œí™”ëœ ë™ì˜ìƒìœ¼ë¡œ ë¶„ì„ ì‹¤í–‰
        result, analyzed_video_local_path = analyze_squat_with_overlay(normalized_video_path)

        yyyymmdd = ts_to_yyyymmdd(timestamp)
        set_no   = get_next_set_no(user_id, user_name, yyyymmdd, exercise_dir)

        analyzed_object_key = f"{ROOT_PREFIX}/{user_id}_{user_name}/{yyyymmdd}/{exercise_dir}/set{set_no}_{timestamp}.mp4"

        s3.upload_file(
            analyzed_video_local_path,
            bucket_name,
            analyzed_object_key,
            ExtraArgs={
                "ContentType": "video/mp4",
                "Metadata": {
                    "user-id": str(user_id),
                    "exercise": exercise_dir,
                    "set-no": str(set_no),
                    "timestamp": timestamp
                }
            }
        )
        print(f"âœ… ë¶„ì„ëœ ë¹„ë””ì˜¤ ì—…ë¡œë“œ ì™„ë£Œ: {analyzed_object_key}")


        # ë¶„ì„ ê²°ê³¼ ì €ì¥ (ì„œë²„)
        analysis_data = {
            "rep_cnt": result["total_count"],
            "feedback": {
                "depth": result["grade"],
                "alignment": "auto",
                "score": result["score"],
                "counts": result["counts"]
            },
            "rep_results": result["rep_results"],
            "analyzed_video_key": analyzed_object_key
        }

        res2 = requests.patch(
            f"{BASE_URL}/workouts/{workout_id}/analysis",
            params={"user_id": user_id},
            json=analysis_data
        )
        print("â–¶ PATCH /analysis:", res2.status_code)
        if res2.status_code == 200:
            print("âœ… ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„±ê³µ:", res2.json())
        else:
            print("âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨:", res2.text)

        # ë¡œì»¬ íŒŒì¼ ì •ë¦¬
        try:
            os.remove(video_path)
            if normalized_video_path != video_path:  # ì •ê·œí™”ëœ ë™ì˜ìƒì´ ë‹¤ë¥¸ íŒŒì¼ì¸ ê²½ìš°
                os.remove(normalized_video_path)
            os.remove(analyzed_video_local_path)
            print(f"ğŸ§¹ ë¡œì»¬ íŒŒì¼ ì‚­ì œ: {video_path}, {normalized_video_path}, {analyzed_video_local_path}")
        except Exception as e:
            print(f"ë¡œì»¬ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

        processed_videos.add(object_key)
        print(f"âœ… ë™ì˜ìƒ ë¶„ì„ ì™„ë£Œ: {object_key}")

        delete_message(msg["ReceiptHandle"])
        return True

    except Exception as e:
        print("âŒ ì˜ˆì™¸ ë°œìƒ:", e)
        print("ğŸ’¬ ì›ë³¸ ë©”ì‹œì§€:\n", msg.get("Body"))

        try:
            if 'video_path' in locals() and os.path.exists(video_path):
                os.remove(video_path)
            if 'normalized_video_path' in locals() and os.path.exists(normalized_video_path) and normalized_video_path != video_path:
                os.remove(normalized_video_path)
            if 'analyzed_video_local_path' in locals() and os.path.exists(analyzed_video_local_path):
                os.remove(analyzed_video_local_path)
            print(f"ì˜ˆì™¸ ë°œìƒ í›„ ë¡œì»¬ íŒŒì¼ ì‚­ì œ")
        except Exception:
            pass

        delete_message(msg["ReceiptHandle"])
        return False

print("ìŠ¤ì¿¼íŠ¸ ë¶„ì„ ì‹œì‘...")
print("â³ ë™ì˜ìƒ ëŒ€ê¸° ì¤‘... (ë™ì˜ìƒì„ ì—…ë¡œë“œí•˜ë©´ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤)")

# í ìƒíƒœ í™•ì¸
try:
    response = sqs.get_queue_attributes(
        QueueUrl=queue_url,
        AttributeNames=['ApproximateNumberOfMessages']
    )
    message_count = int(response['Attributes']['ApproximateNumberOfMessages'])
    print(f"í˜„ì¬ íì— {message_count}ê°œì˜ ë©”ì‹œì§€ê°€ ìˆìŠµë‹ˆë‹¤")
except Exception as e:
    print(f"í ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")

while True:
    msg = get_message()
    if msg:
        print("\nğŸ“¥ ë™ì˜ìƒ ë©”ì‹œì§€ ê°ì§€ë¨!")
        success = process_video_message(msg)

        if success:
            print("âœ… ë™ì˜ìƒ ë¶„ì„ ì™„ë£Œ")
        else:
            print("âŒ ë™ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨")
    else:
        print("ğŸ•“ ë™ì˜ìƒ ì—†ìŒ, ëŒ€ê¸° ì¤‘...")

    time.sleep(5)
